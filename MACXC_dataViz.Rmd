---
title: "Data Summary and Visualization of the MAC PACK 2016-2019"
author: 
- "Edwin Reyes Herrera"
- "Comp Sci 123 Final Project"
output: 
  html_document:
    df_print: paged
    code_folding: show
    toc: true
    toc_float: yes
---
```{python}
# Loading Python Modules
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(style="whitegrid")
```

```{r, message=FALSE, warning=FALSE}
# Loading R libraries
library(tidyverse)
library(lubridate)
library(reticulate)
library(tibble)
```

```{r, echo=FALSE}
knitr::opts_chunk$set(fig.align = "center", fig.show = "hold", fig.height = 7, fig.width = 7,
                      results = "hold")
```


# Introduction

The "Mac Pack" is what the Macalester Men's Cross Country Team is fondly known as, given to our current coach Matt Haugen. He deems the "Mac Pack Era" as the time in which he has been head coach, which has been since the 2002. The team nickname is a play-on-words to indicate that we run in packs, which is important in cross country since the goal is to try to minimize the number of points the team collects in a meet. This analysis uses data on the Macalester's men's cross country team results between 2016 and 2019 that was compiled from the [TFRRS website](https://www.tfrrs.org/index.html) using `Beautiful Soup` in Python. Inspiration from this project stemmed from the various race reports that our coach would send the team after every meet, while the methods to actually implement this were inspired by this [Medium website post](https://medium.com/@viritaromero/web-scraping-5k-race-results-with-python-and-beautifulsoup-d08eba5624eb), which provided very helpful code that I was able to follow closely and cater to my own analysis. The goal of this project was to analyze team and individual performance across my four year tenure at Macalester, looking at metrics such as mile paces, final times, and scoring. The link to the Git Hub repository for this project, which contains this write up, scripts for extracting meet info, the resulting CSV files which contain information on all meets for the four year span, and a Markdown file with sources and references that were used to complete this project is given [here](https://github.com/ereyesherrera/web_scraping_project).

## User’s Manual & Script Contents

### Background Information

The purpose of the program is to extract information on all meets the Macalester Men’s Cross Country Team participated in between 2016 and 2019, which can then be loaded and manipulated to create different data visualizations and summaries, which I have done in the second portion of this project. The code that has been written is specific to the website in which this data is found; results from these meets can be found from other sources, but the TFRRS website mentioned above was chosen because it housed almost all of the meets of interest. As such, the script `main_scraping.py` contains the website links and function calls that extract meet information and other miscellaneous code that need to be run in order to produce a clean data frame only with the target information, which are Macalester race results. This process includes cleaning strings, creating new variables in a data frame and saving them to CSV files, and joining data frames together. 

It is also important to note that a second script named `scraping_missing_meets.py` is a separate program that extracts meet information from two different websites that are different from the TFRRS website. As explained in the script, this is because there are two meets in this four year span that were not found within the TFRRS website. Consequently, there was a need to create two separate specialized programs within this script to correctly extract the information from these websites since the information is presented in different ways across these websites. Again, the code written in this script to extract the information from these websites will work for these websites only. This is a pitfall of web scraping - it involves curating data from many different resources, which entails writing code for every different source that is used to collect this data. Nevertheless, it is still faster than manually creating a CSV file.

The output of these scripts are seven separate CSV files: four CSV files that contain meet information for every year between 2016 and 2019, respectively; two CSV files which contain data on meet results from two different websites that were not found in TFRRS; and one CSV file which is all this data combined into one data frame. Additionally, there is one other CSV file named `OSHKOSH.csv`, which is a CSV file that contains information on another meet that was not found on TFRRS and could not be extracted using the tools I learned for this project. Therefore, this was the only meet in which the results were manually inputted and is thus given in the Git Hub repository in order for the program to run.

### Running the Program

To run the program, the script that needs to be run first is `scraping_missing_meets.py`. This seems counter-intuitive because this is not the script that contains the main program to extract information from the results from TFRRS. However, the resulting CSV files that are created after running this script are needed in order for the `main_scraping.py` to correctly run. Because the end product of this script is to combine all the data frames that are created, all other files must be presented and thus the `scraping_missing_meets.py` must be run first. After running this script, the user should see two new CSV files titled `Augsburg16.csv` and `MIAC17.csv`. Once that script is run and the two files are in the folder, then the user can proceed to run the `main_scraping.py` script, which should take about two minutes since it is extracting data from many different webpages. If the program is successful, then the user should see five more CSV files in their folder: `MeetTimes_16.csv`, `MeetTimes_17.csv`, `MeetTimes_18.csv`, `MeetTimes_19.csv` - which are results from each respective year -  and `MeetALL.csv` - which combines the four CSV files into one. These CSV files can then be used, such as loading them into R for manipulation as I did below. The visualizations and summaries I created here are what I was interested in investigating and also serve the purpose of showing how to use data that was scraped using modules such as Beautiful Soup. As such, this part of the project is there mainly for the user to see what my ultimate goal was, and the way in which I was able to get to that goal was to first scrape the data.

Throughout the process of running these scripts, the user should see the data frames that are created for each meet being outputted - the result of adding print statements in the script to show the data frames that are being created from the web pages that are being extracted for information. There are also sections and comments which indicate what is being done at each step of the program. In the `main_scraping.py` script, the first section is what I have described as a “first pass at web scraping.” This section extracts information from a website with results from a meet in 2019, but the code is long and not concise. This was merely to get familiar with the types of functions I would need to make this process faster. The next section is two functions I created to quickly extract information from the websites and then filter out all results but Macalester’s, respectively. The following section is, then, using those functions to extract the data from the rest of the meets in 2019. The subsequent sections are extracting information from the other years. The difference between these sections and the section which extracts data from 2019 is that after collecting information on 2019 results, I realized that another way I can reduce the amount of code I am writing is placing all the website links in a dictionary with their respective keys that indicate which meet it is, then iterating over the dictionary using a for loop to create all the data frames and combining them at the end. The final section is simply taking the four data frames and combining them into one final data frame with all results from the four years. I could have gone back and implemented this method to the first sections, but I wanted to show my thought process and demonstrate how the project changed and grew as I progressed through it. There are also two, larger sections that are commented out in the `main_scraping.py` script that are what the `scraping_missing_meets.py` script contains and can be run through that file.

Testing this program consisted of using the guess and check method, which was commenting out portions of the script and adding print statements to ensure that the correct data was being extracted before continuing on to the next step. This was important because the websites in which the data was being extracted from had results from all other men’s teams and also results from the women’s race. I am very confident that I successfully extracted all of Macalester men’s results since I am familiar with how many members were on each team and how many observations a data frame would need to have, for example. However, if I were to continue with this project and look at all results and not only Macalester results, then I would need to double-check that every runner for every team at a given meet were present in the resultant data frame.

A user can first download the two scripts and the `OSHKOSH.csv` from the repository into their directory of choice on their own computer. (Click on the “Raw” button, then Right-Click on the page and select “Save As..”). If a user is completing this step with IDLE, then all they need to do is open the `scraping_missing_meets.py` script and choose “Run Module” from the Run menu, then do the same for the `main_scraping.py` script. If the user is using an IDE such as PyCharm, then it would be necessary to create a project and move the files mentioned earlier into the project directory, then open the files in the window and running them. Finally, a user can use Terminal to run the scripts by executing the command `python scraping_missing_meets.py` for example. It is important to note that in order for this command to work, the user must be in the working directory of wherever all the files are saved on the computer. This [resource](https://pythonbasics.org/execute-python-scripts/) is very helpful in understanding how to complete this.

### Final Thoughts 

In conclusion, I was able to combine my interests in data science and the tools I learned in this course to pick up a new skill and produce a report based on the data I collected, found below. The learning curve was steep in that I relied on online documentation and help to understand how to implement my ideas, but it ultimately allowed me to see how to both seek resources that were exactly what I needed for a specific portion of my project and how to piece together different resources to be applied to my own project and analysis. As mentioned above, the main script shows a progression of how my program changed and become more simple and concise. One thing I would do differently next time is do more exploratory work and experiment with different methods to reach a result that I liked best and use that for the entirety of the project. It became difficult to keep track of sections that used different methods and tools. When I had a bug in one section, I had to make sure another section also worked because it was using different techniques, so I most likely did more work than I needed to in the end. This also applies to my decision of using R Markdown to create my final report. It would have been simpler to use PyCharm for everything, but I desired a final product which neatly showed my results apart from the script which scrapes data. This meant jumping back and forth between language engines and syntax, which also complicated the project.

Nevertheless, I was surprised to see how seamless it was to use both R and Python to create my final product. I am more confident at this point using R because I have been using it for longer than Python, but creating functions is much more user friendly in Python. Similarly, creating scripts that simply can be run and create output is, in my opinion, more intuitive and straightforward in Python. I always wondered which engine was better to use, but now I feel like I do not have to choose between the two and can use both to my advantage in future projects. I was also surprised to see how my final report below as became a tutorial for combining the two languages of sorts. This was mainly for a reader who is wondering what each chunk of code does and what it produces, but it was also for me so that I have it for reference if something like this arises in the future.

There are many “future extensions” I can consider for this project. For example, the next obvious aspect to analyze are results from the Macalester women’s team for this time range as well. This would mean creating an entirely different script to extract these results then combining the results of that script with what I already have, or updating the script I have now to automate the process of putting the two elements together. In addition, a much bigger project would be to analyze how each team and their runners in our conference performed at each of our conference championship meets for these four years. I can envision an analysis similar to the one found below, but instead comparing results across different teams and years. Finally, the bigger task would be to analyze each Mac Pack team performed since our head coach has been at Macalester and determining the top 10 fastest runners in Mac Pack history or understanding how the Mac Pack has historically placed in the conference championships, for example.

The following sections are the analysis I chose to perform on the data I was able to extract using the scripts explained above.

# Analyzing the 2019 Cross Country Season

This reads in the csv file that was created from the Python script dedicated to web scraping meet results and creating a full data frame containing information on all the meets that the men's cross country team competed in this year. It drops an unused variable left over from that process.

```{python}
MeetInfo = pd.read_csv("data/MeetTimes_19.csv")
MeetInfo = MeetInfo.drop(['Unnamed: 0'], axis=1)
```

After reading the data frame using Python's `pandas` module, we are able to access it in R using the `reticulate` package and convert some columns into characters, in which Python reads in as a list. Displayed below is the data frame of 2019 results that was scraped from the Python script using `Beautiful Soup`.

```{r}
# 2019 Results
MeetInfo <- py$MeetInfo %>%
  mutate_if(is.list,as.character)

MeetInfo
```

Using Python's `seaborn` module, we can begin to visualize every runner's performance throughout the year. Below is a line plot showing the place each runner was on the team for every meet. The lower the place, the faster the athlete ran. We can notice that some athletes only have few data points on their graph - this reflects a missed meet. Looking at my own performance, we can see that I was consistently the same place on the team (4th) for all but two meets - the Summit Cup and the Central Region meet.

```{python, message = FALSE, warning = FALSE}
# Runner Performance 2019
g = sns.FacetGrid(MeetInfo, col="LASTNAME", hue = "LASTNAME", col_wrap=5)
(g.map(plt.plot,"MEET", "TEAMPLACE", marker=".")
.set_axis_labels("", "Team Place")
.set_xticklabels([]))
plt.show()
```

Moreover, we can continue to visualize how each runner performed by plotting every runner's place on a scatter plot using the meets on the x-axis. In this plot, we can better see how every runner performed relative to all other teammates and also see which runners performed better than others in a given meet. For the most part, we can see those runners that were placed 1st through 5th remained consistent for the entire year, only with some variation. This is neat because it uses `ggplot` in R to create a visualization from a data frame that was created in Python.

```{r}
ggplot(MeetInfo, aes(x = MEET, y = TEAMPLACE, label = LASTNAME, color = LASTNAME)) +
    geom_text(size = 3) +
    theme_minimal() +
    theme(axis.text.x=element_text(angle = 90, size = 7), legend.position ="none",
          title = element_text(face="bold"), axis.text = element_text(face="bold")) +
    labs(x = "Meet", y = "Team Place", title = "Performances for Every 2019 Meet") +
    scale_y_continuous(breaks = seq(1,21, 1)) + 
    scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", 
                                "Running of the Cows (Carleton)", 
                                "Blugold Invitational", 
                                "Jim Drews Invitational (Lacrosse)", "MIAC", 
                                "Central Region"))
```

From the plot above, we can see that there were some meets in which not all runners competed. As such, the Python code below returns the count for the number of meets that every runner competed in. We can see some variation in this; if a runner ran seven meets, that means that they ran in all of the "regular season" meets, plus the Central Region Meet, in which you have to qualify for. Summarizing this information was converted back into a `pandas` data frame for ease of manipulation later.

```{python}
# Summarizing the number of meets each runner competed in
runnerMeets = pd.DataFrame(MeetInfo.LASTNAME.value_counts())
runnerMeets.columns = ["Count"]
runnerMeets
```

I was interested in analyzing how many points every runner that ran in every meet (including the Central Region meet) this year accumulated. First, we retrieve a list of the names of the runners that ran in all 7 meets by filtering and save it into an object called `scorers`. The `.index` was used to extract the names, as the names were being used as the index of the rows in the above data frame.

```{python}
# List of runners that ran all seven meets
scorers = list(runnerMeets[runnerMeets.Count == 7].index)
scorers
```

Then, we take the original `MeetInfo` data set that has all the information of 2019 meets and filter to only reflect runners that were in the top 5 for the team in each meet. This reflects those runners that contributed to the overall team score for each meet since only the top 5 runners on each team score. This takes advantage of the `.isin()` function of pandas, which looks to filter the column of `TEAMPLACE` satisfy the condition that it is between 1 and 5.

After, we filter again, but this time use the `scorers` list created above to filter and only keep the names of the runners that were in the top 5 runners on the team, and now also that ran in all 7 meets of the year. Finally, we summed up the total score each runner accumulated throughout the year. The `reset_index()` converts the names that are the row's index to a column.

```{python}
# Scores of Top 5 runners
top5Scores = MeetInfo[MeetInfo.TEAMPLACE.isin(range(1,6))]
top5Scores = top5Scores[top5Scores.LASTNAME.isin(scorers)]
top5Scores = top5Scores.groupby("LASTNAME").sum()[['SCORE']].reset_index()
top5Scores
```

We can also visualize the summary output above in a bar plot. What we can deduce from the summary table and the bar plot is that these were the runners that were consistently in the top 5 runners on the team for every meet. It was important to only consider those runners that ran in all meets. This is because if there was a runner that only ran in some meets, and was a scoring runner, then their point accumulation would be lower than everyone else's. 

In addition, we can also see that their total point accumulation reflects what place on the team they usually finished as at the end of the race. What is interesting to note is that Lepak usually was the first to finish for our team, but had some races in which he was second or third, which is why he is the teammate that scored the second least points on the team, getting edged out by Johnson in the end.As such, this plot does a great job of indicating the trajectory of the runners and the place they were on the team. We can see the same effect happen between myself and O'Donnell-Hoff, as I was usually the 4th to finish on our team and he was the 5th, but the margin being so close reflects how we traded positions in some meets. In the end, taking into consideration all meets, Johnson was the number one runner for the 2019 year even if he did have some races where he did not finish number one. Nevertheless, this is a hard metric to use when comparing runners since every meet had very different field sizes.

```{python}
# Points for Top 5 runners
plot = sns.barplot(x="LASTNAME", y="SCORE", data=top5Scores, order= ["Johnson", "Lepak", "Mayse", "Reyes Herrera", "O'Donnell-Hoff"])
plot.set_title("Points Accumulated at 2019 Meets for Top 5 Runners", 
  fontsize = 15, weight = "bold")
plot.set_xlabel("Runner", fontsize = 15, weight = "bold")
plot.set_ylabel("Points", fontsize = 15, weight = "bold")
```

From there, I was also curious to analyze everyone's performance based on their times for each race. The problem was that when the data was scraped, the times were saved as strings, so there was a need to convert these strings into numeric data. Luckily, R has a package called `lubridate` that is exceptional for working with dates and times.

Using the Python data frame, we update the `MeetInfo` using R and `lubridate` to convert the times reflected in the variables of `TIME` (final time for a meet) and `Avg. Mile` (average mile during a race) from strings to numeric data. We indicate that we want our data to be converted to minutes.

```{r, warning=FALSE}
# Converting time strings into minutes
MeetInfo <- MeetInfo %>%
  mutate(TIME = time_length(ms(TIME), unit = "minute"),
         `Avg. Mile` = time_length(ms(`Avg. Mile`), unit = "minute"))

MeetInfo
```

Using the updated data frame above, we are able to make a similar line plot to the one above, this time plotting every runner's trajectory based on their total time for a race. It is important to note that not all races were the same distance - some were only 4 miles, while the typical race is an 8K. To account for this (i.e. avoid any misleading information on the plot when someone's time suddenly decreases), we order the x-axis so as to place those meets that were only 4 miles at the beginning.

```{r, warning=FALSE}
#Visualizing runner performance by final race time for each race
ggplot(MeetInfo, aes(x = MEET, y = TIME, color = LASTNAME, group = LASTNAME)) + geom_point() +
    geom_line() +
    theme_minimal() +
    facet_wrap(vars(LASTNAME), ncol = 4) +
  labs(x = "Meet", y = "Race Time", title = "Race Time for Every 2019 Teammate",
       subtitle = "Every Meet") +
    theme(axis.text.x=element_text(angle = 90), legend.position ="none",
          strip.text = element_text(face="bold"), axis.title = element_text(face="bold"),
          title = element_text(face="bold")) +
    scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "MIAC", "Central Region"))
```

Another way to control for difference in distances for meets is to plot a runner's trajectory using their average mile pace for a race. In this way, all races are on the same scale and this gives a better perspective on whether a runner ran faster or slower relative to other meets. Looking at my own progression, I generally became faster as the year went on, with a small increase in time in the second and 3rd meets, and again at the Central Region Meet. (Note: the order of the x-axis also reflects the order of meets that we competed in, by chance! So this does in fact show progression throughout the year in chronological order). The absence of dots or breaks in the line show missed meets or DNFs (did not finish).

```{r, warning=FALSE}
# Visualizing runner performance based on average mile for each race
ggplot(MeetInfo, aes(x = MEET, y = `Avg. Mile`, color = LASTNAME, group = LASTNAME)) + geom_point() +
    geom_line() +
    theme_minimal() +
    facet_wrap(vars(LASTNAME)) +
    labs(x = "Meet", y = "Average Mile Pace", 
         title = "Average Mile Pace for Every 2019 Teammate", subtitle = "Every Meet") +
    theme(axis.text.x=element_text(angle = 90), legend.position ="none",
          strip.text = element_text(face="bold"), axis.title = element_text(face="bold"),
          title = element_text(face="bold")) +
    scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Running of the Cows (Carleton)","Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "MIAC", 
                                "Central Region"))
```

Another neat thing about this analysis is that even though we changed the original data set that was created in Python in R, we are able to return that data frame so that the Python engine can begin using it again, which is what is done below.

Now that we have visualized every runner's individual performance for the 2019 year, I wanted to analyze the time gap between the first and the 5th runner on the team. Generally, the bigger the gap, the more points that the team accumulates and the worse that the team places overall in a meet.

First, we return the updated data frame of `MeetInfo` into Python after manipulating it in Python and assign it to the variable `avgTime` and filter to only have the top 5 runners for each meet. Then, we group by every meet and use `pandas` `agg()` function to apply three summary statistics for each meet: the fastest time at every meet (min), the slowest time at every meet (max), and the average time at every meet (mean). Then we take advantage of `pandas` `.assign()` function to create a new variable called `gap` that takes the difference in the slowest and fastest time to find the gap in minutes for every meet.

We can observe that the meet which had the smallest gap between the first and last runner that scored was the Twin Cities Invitational, which was our first race of the year. The gap is about 0.75 minutes, which is about 45 seconds. This is intuitive considering that this was also the meet in which we placed the highest (2nd place overall). This metric, again, controls for the fact that some races were different distances.

Looking at the races that were 8k distances, we see that the best team finish was the MIAC meet, which was our conference championships. Interestingly, this was a meet in which all runners finished closest to each other, but the average time for this meet is only the third fastest out of all the meets. This means that everyone ran slower at this meet even though the gap was smaller, leading to a worse finish than what is seen on the surface.

```{python}
# Min, max, Average Time and Gap for each meet in 2019

avgTime = r.MeetInfo[r.MeetInfo.TEAMPLACE <= 5]
avgTime = pd.DataFrame(avgTime.groupby("MEET").
  agg({"TIME": ["min", "max", "mean"]}).
  rename(columns = {"min":"Time_min", "max":"Time_max", "mean": "AvgTime"}))

avgTimeSummary = avgTime["TIME"].assign(gap = avgTime["TIME"]["Time_max"] - avgTime["TIME"]["Time_min"])

avgTimeSummary = avgTimeSummary.reset_index()
avgTimeSummary
```

We can also calculate the average gap between the 1st and 5th runner for the entire year, which ended up being almost 1 minute and 15 seconds.

```{python}
# Getting average gap between 1st and 5th man for 2019
avgTimeSummary["gap"].mean().round(4)
```

# Analyzing the 2016-2019 Seasons

Now that we have analyzed performances for the 2019 cross country season, we can apply the same analysis to *all* races during my four years here at Macalester.

First, we load the data set containing information on all meets for the four years using Python and assign it to `MeetALL`.

```{python}
# Results for 2016-2019 Seasons
MeetALL = pd.read_csv("data/MeetALL.csv")
MeetALL = MeetALL.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)
```

Then we also create it as an R data frame to be able to easily manipulate it.

```{r, warning=FALSE}
# Results for 2016-2019 seasons
MeetALL <- py$MeetALL %>%
  mutate_if(is_list, as.character)

MeetALL
```

Now that it is an R object, we can again use the `lubridate` package to convert the average mile pace and total time for every meet to numeric data on the minutes scale from string objects just as above.

Another step we must take is collapsing levels of a factor that indicate the same thing, particularly in the `YEAR` variable. For example, `SR` and `SR-1` both correspond to a runner whom is in his senior year, so we must combine all instances of this - and for the other years also - using the `fct_collapse` function from R.

```{r, warning=FALSE, message=FALSE}
# Converting Time and Average Mile columns to integers using lubridate
MeetALL <- MeetALL %>%
  mutate(TIME = time_length(ms(TIME), unit = "minute"),
         `Avg. Mile` = time_length(ms(`Avg. Mile`), unit = "minute"))

# Collapsing factors that mean the same thing
MeetALL <- MeetALL %>%
  mutate(YEAR = fct_collapse(MeetALL$YEAR, `SR-4` = c("SR", "SR-4"), 
                             `JR-3` = c("JR", "JR-3", "JR-1"),
                             `SO-2` = c("SO", "SO-2", "1"), `FR-1` = c("FR", "FR-1")))

MeetALL
```

Then, the updated `MeetALL` data frame is called back into Python, and we find the slowest, fastest, and average time for each meet for every year only for the top 5 runners in each meet, and also calculate the gaps between the first and fifth runner for every meet - this is all saved into `avgTimeSummaryALL`. An additional summary statistic that we will calculate here is the average mile pace for every meet for every year.

```{python}
# Calling data frame back into python
# Filtering Top 5 Runners
# Finding summary statistics

avgTimeALL = r.MeetALL[r.MeetALL.TEAMPLACE <= 5]
avgTimeALL = pd.DataFrame(avgTimeALL.groupby(["MEET", "DATE"]).agg(
  Time_min = ("TIME", "min"),
  Time_max = ("TIME", "max"),
  Time_avg = ("TIME", "mean"),
  Avgmile = ("Avg. Mile", "mean")).reset_index())

avgTimeSummaryALL = avgTimeALL.assign(
  gap = avgTimeALL["Time_max"] - avgTimeALL["Time_min"]
)

pd.set_option('max_columns', 7)
avgTimeSummaryALL
```

Now that we have information on all four years, we can determine which Mac Pack team in this four year span was the "best" in terms of gap between the first and last runners who score. We group by year and find the average gap for every meet for every year and visualize the results in a bar plot. We can see that during my four years at Macalester, the "best" team was in 2018 with an average gap of about 50 seconds, followed by the 2019 team with an average gap of about 1 minute and 15 seconds. However, the 2019 team had the best gap by only a slight margin when compared to the 2016 team.

I was wondering which team also contributed the least amount of points throughout the year, but teams were unable to be compared since some teams ran in more meets than others, so the point accumulation would not be representative of performance in this case.

```{python}
# Calculating Average Gap between runners for each Year
gapsALL = pd.DataFrame(avgTimeSummaryALL.groupby("DATE")
  .mean()["gap"]).reset_index()
  
plot = sns.barplot(x="DATE", y = "gap", data = gapsALL, order= [2018.0, 2019.0, 2016.0, 2017.0])
plot.set_title("Average Gap (min) between 1st Runner and 5th Runner", 
  fontsize = 15, weight = "bold")
plot.set_xlabel("Year", fontsize = 15, weight = "bold")
plot.set_ylabel("Gap (Minutes)", fontsize = 15, weight = "bold")
```

We can also visualize race performance using the data we gathered above on average time and average gap for every meet for every year. The plot below shows the average time for every meet across all four years. Again, those races that were not an 8k distance (now including 4 mile and 5k races) were place at the beginning of the plot (going left to right) to avoid any misconceptions about the time.

In this plot, we can observe that the 2018 and 2019 years ran less in meets than in 2017 or 2016 teams, which may be a factor in why their gaps were much better. The 2018 team's times stayed very consistent, while the 2019 team had slightly more variability in times. From this plot, we can see that the 2017 team had the fastest average time at the MIAC meet, followed closely by the 2019 team. In addition, the 2018 team had the fastest average time at the Central Region meet followed by 2017; these two meets are essentially the "playoffs" and the ones that really matter, so to speak. The second plot communicates the same information except all the years are visualized on the same plot, making it easier for comparison.

```{r}
# Average Race Time Plot across Years
py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = Time_avg, color = factor(DATE), group = DATE))+
  geom_line() +
  geom_point() +
  facet_grid(rows = vars(DATE)) +
  labs(x = "Meet", y = "Average Time (minutes)", color = "Year", title = "Average Time", subtitle = "For Every Meet in a Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90),
        axis.title = element_text(face="bold"),
        title = element_text(face="bold")) +
  scale_y_continuous(breaks = seq(20,32,2)) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))

py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = Time_avg, color = factor(DATE), group = DATE))+
  geom_line() +
  geom_point() +
  labs(x = "Meet", y = "Average Time (minutes)", color = "Year", title = "Average Time", subtitle = "For Every Meet in a Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90),
        axis.title = element_text(face="bold"),
        title = element_text(face="bold")) +
  scale_y_continuous(breaks = seq(20,32,2)) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))
```

Furthermore, we can also create a visualization of all the time gaps for every meet in every year. Interestingly, we see that the best team finish in this four year span was in 2018 for the Griak meet, where the gap was only 30 seconds. We can also observe that the gaps in 2018 always were around a minute or below, while the gaps in 2019 were variable and consistently over a minute. Moreover, the 2019 team had the best gap at the MIAC meet, but then tumbled and is tied for worst gap at the Central Region meet. The 2017 team followed the same trajectory. We can deduce that the 2018 team did the best overall at the Central Region meet, then. Again, the second plot allows for more concrete comparisons.

```{r}
# Average Gap across years plot
py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = gap, color = factor(DATE), group = DATE))+
  geom_line() +
  geom_point() +
  facet_grid(rows = vars(DATE), ) +
  labs(x = "Meet", y = "Gap (minutes)", color = "Year", title = "Gap Between 1st and 5th Runner", subtitle = "For Every Meet in a Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90),
        axis.title = element_text(face="bold"),
        title = element_text(face="bold")) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))

py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = gap, color = factor(DATE), group = DATE))+
  geom_line() +
  geom_point() +
  labs(x = "Meet", y = "Gap (minutes)", color = "Year", title = "Gap Between 1st and 5th Runner", subtitle = "For Every Meet in a Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90),
        axis.title = element_text(face="bold"),
        title = element_text(face="bold")) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))
```

Finally, we can also calculate average mile pace for the scoring runners for every meet for every year in this time span. This again would place all meets on the same scale and would be a better metric to compare performance at every meet for each year. It is interesting to note that the 2018 team had the third fastest average mile as a team at MIAC, but then went on to have the fastest average mile as a team at the Central Region Meet. The 2019 team, as mentioned before, declined in speed. This continues to affirm that the 2018 team did the best at the Central Region meet and general had an upward trajectory.

```{r}
# Average Mile Pace across years plot
py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = Avgmile, color = factor(DATE), group = DATE)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90),
        axis.title = element_text(face="bold"),
        title = element_text(face="bold")) +
  labs(x = "Meet", y = "Average Mile", color = "Year", 
       title = "Overall Average Mile for Team", subtitle = "For Every Year") +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))
```

From the plots above, we can see how each team did compared to others for the same meets. As was mentioned before, the 2018 team in general was the "best" in most of the metrics above, though in some other years, the team had either a fast average time for a meet or a smaller gap between runners. It is important to take into consideration both gap and overall average mile for the team because a gap between runners can be small, but if they all ran relatively slow, then the point totals would be higher. Similarly, if the average time for a meet was very fast, but the gap was large, then the point total would also be large. As such, we can only deduce from the beginning of this analysis that the team with the smallest gap between runners was the 2018 squad. However, taking into consideration the plots below, we see that the 2019 team had the fastest overall average mile and the second fastest overall average time as a team. Therefore, the 2019 in reality may have been slightly better than the 2018 team, though the 2018 team did have the best finish in Mac Pack team history, which may have been what gave them the margin in having the best average gap. Of course, every team ran in different meets throughout the year and some ran more than others, so some of these comparisons may not be fair. Furthermore, these metrics are very similar to each other when comparing across teams, so in the end, this may be attributed to consistency in team structure and coaching. However, this analysis still is able to visualize the team's trajectory throughout the year.

```{python}
# Bar plot for average mile pace across years
avgMileALL = pd.DataFrame(avgTimeSummaryALL.groupby("DATE")
  .mean()["Avgmile"]).reset_index()

avgMileALL
  
plot = sns.barplot(x="DATE", y = "Avgmile", data = avgMileALL, order= [2019.0, 2018.0, 2017.0, 2016.0])
plot.set_title("Average Mile for all Meets", fontsize = 15, weight = "bold")
plot.set_xlabel("Year", fontsize = 15, weight = "bold")
plot.set_ylabel("Average Mile", fontsize = 15, weight = "bold")
```

```{python}
# Bar plot for average race time across years
avgTimeALL = pd.DataFrame(avgTimeSummaryALL.groupby("DATE")
  .mean()["Time_avg"]).reset_index()

avgTimeALL
  
plot = sns.barplot(x="DATE", y = "Time_avg", data = avgTimeALL, order= [2017.0, 2019.0, 2016.0, 2018.0])
plot.set_title("Average Time for all Meets", fontsize = 15, weight = "bold")
plot.set_xlabel("Year", fontsize = 15, weight = "bold")
plot.set_ylabel("Average Time", fontsize = 15, weight = "bold")
```

As a final aside for this section, I wanted to see the break down of class years that qualified to race for the Central Region Meet for every year. As mentioned before, a runner must qualify for the Central Region  Meet by finishing in the top seven on the team at the MIAC Championships meet. As such, we filter to only have the Central Region meet, then group by `DATE` and `YEAR` and count the instances of each class year in a given year for that meet. We can neatly view this information by making the resultant data frame into a wider format.

From the results above, we can see that the 2017 had no seniors that qualified for the Central Region Meet, while the 2019 had five seniors in contrast. The 2018 team had representation from all classes, but there was a mistake in how the officials reported the results for Macalester at this meet, as they listed one of the seniors on that team as a first year. So in reality, there were 3 seniors, 1 junior, 2 sophomore, and 2 first-years for 2018 at the Central Region meet.

```{python}
year_breakdown = r.MeetALL[r.MeetALL.MEET == "Central Region"]
year_breakdown = year_breakdown.groupby(["YEAR", "DATE"]).size().reset_index()
year_breakdown.pivot(index= "DATE", columns = "YEAR", values = 0)
```


# Analyzing the Class of 2020

A final aspect of this web scraping project I was interested in investigating was visualizing the trajectory of the Class of 2020 teammates during our four years at Macalester. Using Python, we create a list with the remaining Class of 2020 teammates.

```{python}
# List of Senior runners
class_2020 = ["Reyes Herrera", "Lepak", "Jarka-Sellers", "Milner", "Bildsten", "O'Donnell-Hoff", "Hernandez"]
```

Then using the list above, we filter the `MeetALL` data from above based on this list using `.isin()` and saved this new data frame to an object called `seniors`. This data frame now contains information on race results over four years only for the Class of 2020.

```{python}
# Filtering senior runners
MeetALL = r.MeetALL
seniors = pd.DataFrame(MeetALL[MeetALL.LASTNAME.isin(class_2020)])
seniors
```

Now only having information on the Class of 2020, we plot each of the seven members' performances using their final time for every meet between the span of 2016-2019. Again, non-8K races were placed left most to avoid any confusion about discrepancies in race times.

```{r, warning=FALSE}
# Class of 2020 Race trajectory plot
py$seniors %>%
  ggplot(aes(x = MEET, y = TIME, color = LASTNAME, group = LASTNAME)) +
  geom_line() +
  geom_point() +
  facet_grid(rows = vars(DATE), cols = vars(LASTNAME)) +
  theme_minimal() +
  labs(y = "Final Race Time", color = "Runner", 
       title = "Class of 2020 Race Time For Every Meet", 
       subtitle = "2016-2019") +
  theme(axis.text.x = element_text(angle = 90, size = 5),
        title = element_text(face = "bold"),
        axis.title = element_text(face = "bold")) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))
```

From there, I wanted to see how the average time for a given year changed for each member of the Class of 2020. We group by the team member and the date and calculate the average race time and average mile pace for each team member for every year.

```{python}
# Average mile pace and race time for seniors for all years
seniorsAvg = seniors.groupby(["LASTNAME", "DATE"]).agg(
  Time_avg = ("TIME", "mean"),
  Avgmile = ("Avg. Mile", "mean"))
seniorsAvg = pd.DataFrame(seniorsAvg.reset_index())
seniorsAvg
```

When visualizing this, we can see for the most part that everyone had a falling trend, which means that in general, all members became faster over the course of the four years.

```{r}
# Average Race Time per year plot
py$seniorsAvg %>%
  ggplot(aes(x = factor(DATE), y = Time_avg, color = LASTNAME, group = LASTNAME)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(x = "Average Race Time", y = "Year", color = "Runner", 
       title = "Average Race Time For 2016-2019 Seasons", subtitle = "Class of 2020") +
  theme(axis.title = element_text(face="bold"), title = element_text(face="bold"))

# Average Mile Time per Year plot
py$seniorsAvg %>%
  ggplot(aes(x = factor(DATE), y = Avgmile, color = LASTNAME, group = LASTNAME)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(x = "Average Mile", y = "Year", color = "Runner", 
       title = "Average Mile Pace For 2016-2019 Seasons", subtitle = "Class of 2020") + 
  theme(axis.title = element_text(face="bold"), title = element_text(face="bold"))
```

In addition, we can also determine where and when each member of the Class of 2020 had their fastest and and slowest race. For this analysis, however, it is important to filter out the races that were not an 8K distance, since those races would be the fastest for everyone. More importantly, the culmination of a season is getting a personal best in the 8k. 

An approach to do this is how we handled filtering out the Class of 2020 using the `.isn()` function and passing through a list. However, another method is creating a new variable `Type` that designates if a race was an 8K, or another distance, as seen below using `numpy` and its `select` function.

```{python}
# Filtering 8K races
conditions = [
    (seniors["MEET"] == "Summit Cup") | (seniors["MEET"] == "Twin Cities Invitational"),
    (seniors["MEET"] == "Augsburg Open")
    ]
choices = ['4 Mile', '5K']

seniors['Type'] = np.select(conditions, choices, default='8K')

seniors
```

From there, we can filter using the new `Type` column and only selecting 8K races. Afterwards, we can group by runner and find the `max` and `min` for final race time, reflecting the fastest and slowest race times, respectively.

```{python}
# Fastest and slowest 8K race for each runner
seniors_8K = seniors[seniors["Type"] == "8K"]

seniors_best = seniors_8K.groupby("LASTNAME").agg(
  Slowest_Time = ("TIME", "max"),
  Fastest_Time = ("TIME", "min")).reset_index()

seniors_best
```

A way to visualize every senior's fast and slowest race is to change the data frame from above to be in a "longer" format so that we have a column that designates if it was a runner's fastest or slowest time and a column that is the time in minutes. The code below uses the `stack()` function from `pandas` to create new variables called `Type` and `Race Time` which allows us to create a double bar graph for all runners showing their fastest and slowest times.

```{python}
# Pivot Longer
seniors_best.set_index("LASTNAME").stack().reset_index().rename(columns = {0:"Race Time", "level_1":"Type"})

# Bar plot for fastest and slowest 8K times
plot = sns.barplot(x="LASTNAME", y="Race Time", hue= "Type", data= seniors_best.set_index("LASTNAME").stack().reset_index().rename(columns = {0:"Race Time", "level_1":"Type"}))
plot.set_title("Fastest and Slowest 8K Times for Class of 2020", 
  fontsize = 15, weight = "bold")
plot.set_xlabel("Runner", fontsize = 15, weight = "bold")
plot.set_ylabel("Time", fontsize = 15, weight = "bold")
```

The using R, we are able to see all the details from a senior's fastest and slowest races - namely, when and where those races were. This is accomplished using R's `slice` and `which.min` functions. We can observe, for example, that I had my fastest race at the Blugold Invitational in 2019 and my slowest at the St. Olaf Invitational in 2017.

```{r}
# Using R to see Meet and Date when finding min and max

# Fastest Times
py$seniors_8K %>%
  group_by(LASTNAME) %>%
  slice(which.min(TIME)) %>%
  select(LASTNAME, MEET, TIME, DATE)

# Slowest Times
py$seniors_8K %>%
  group_by(LASTNAME) %>%
  slice(which.max(TIME)) %>%
  select(LASTNAME, MEET, TIME, DATE)
```

In addition, now that we have a data frame in which all the non-8K meets are filtered out, we can also use `seaborn` to create a box plot to show the distribution of race times for each runner throughout his four years. We can see that Lepak had the lowest range, while Hernandez had the largest.

```{python}
#Range of Times for Class 0f 2020 throughout the years
plot = sns.boxplot(x= "LASTNAME", y= "TIME", data = seniors_8K)
plot.set_title("Range of 8K Times for Class of 2020 Runners", fontsize = 15, weight = "bold")
plot.set_xlabel("Runner", fontsize = 15, weight = "bold")
plot.set_ylabel("Race Time", fontsize = 15, weight = "bold")
```

# Reanalyzing 2016-2019 Seasons Using only 8K times

Now that we have a method to only analyze 8K times, we return to comparing all four seasons based only on 8K times. We will repeat the analysis and visualizations above, but this time using only 8K meets.

We are first interested in comparing the range of 8K times for every year, so we take the original `MeetALL` data frame that was manipulated in R to convert the times into numeric types, call it back into Python, and filter out the non-8K races using the list and `.isin()` method. It is important to note that the tilde here is needed, which is equivalent to `=!`.

```{python}
# Filtering 8K races
non8K = ["Summit Cup", "Twin Cities Invitational", "Augsburg Open"]
avgTimeALL_8K = r.MeetALL[r.MeetALL.TEAMPLACE <= 5]
avgTimeALL_8K = avgTimeALL_8K[~avgTimeALL_8K.MEET.isin(non8K)]
```

Then, we are able to calculate summary statistics and use a `seaborn` box plot to understand the range of 8K times for each year. We can see that the 2016 team had the highest range in times for the top 5 runners as the standard deviation is about 0.85, while 2018 had the lowest range in times. Nevertheless, the mean and median times for 2018 are higher than that of the 2019 times, which means the the 2019 team had faster times at meets even though the 2018 team had a smaller range.

```{python}
#Range of 8K times for each Year
avgTimeALL_8K.groupby("DATE").agg(
mean = ("TIME", "mean"),
median = ("TIME", "median"),
sd = ("TIME", "std")
)

plot = sns.boxplot(x= "DATE", y= "TIME", data = seniors_8K)
plot.set_title("Range of 8K Times for 2016-2019 Seasons", fontsize = 15, weight = "bold")
plot.set_xlabel("Year", fontsize = 15, weight = "bold")
plot.set_ylabel("Race Time", fontsize = 15, weight = "bold")
```

Now, using the technique from the previous section we take the `avgTimeSummaryALL` data frame that summarizes the average race time, mile pace, and gap between runners for all meets across the four years created in the second section above and add a new variable called `Type` that designates the distance of the race. We can keep in mind that this data frame had already filtered to only reflect the averages for those runners in the top 5 on the team.

```{python}
conditions = [
    (avgTimeSummaryALL["MEET"] == "Summit Cup") | (avgTimeSummaryALL["MEET"] == "Twin Cities Invitational"),
    (avgTimeSummaryALL["MEET"] == "Augsburg Open")
    ]
choices = ['4 Mile', '5K']

avgTimeSummaryALL['Type'] = np.select(conditions, choices, default='8K')
avgTimeSummaryALL
```

Then using the new column, we choose only the races which are 8K distance to analyze.

```{python}
#Filtering 8K races from summary of average mile pace, race times, gap for all years
avgTimeSummaryALL_8K = avgTimeSummaryALL[avgTimeSummaryALL["Type"] == "8K"].reset_index()
avgTimeSummaryALL_8K = avgTimeSummaryALL_8K.drop(['index'], axis=1)
```


Finally, we compute the average race time, mile pace, and gap between runners for every year and visualize the results.

```{python}
# Average Race Time for each meet for every year
avgTimeALL_8K = pd.DataFrame(avgTimeSummaryALL_8K.groupby("DATE")
  .mean()["Time_avg"]).reset_index()

avgTimeALL_8K
```

```{python}
# Average Mile Pace for each meet for every year
avgMileALL_8K = pd.DataFrame(avgTimeSummaryALL_8K.groupby("DATE")
  .mean()["Avgmile"]).reset_index()

avgMileALL_8K
```

```{python}
#Average Gap between runners for each meet for every year
gapsALL_8K = pd.DataFrame(avgTimeSummaryALL_8K.groupby("DATE")
  .mean()["gap"]).reset_index()
gapsALL_8K
```

```{r}
# Visualizing Average Time, Average Mile and Gaps for every year (only 8K)
p1 <- py$avgTimeALL_8K %>%
  ggplot(aes(x = factor(DATE), y = Time_avg, fill = factor(DATE))) +
  geom_col() +
  theme_minimal() +
  labs(x = "Year", y = "Race Time", title = "Average Race Time") +
  scale_x_discrete(limits = c("2019", "2017", "2018", "2016")) +
  theme(legend.position = "none", title = element_text(face="bold"), 
        axis.title = element_text(face="bold"))

p2 <- py$avgMileALL_8K %>%
  ggplot(aes(x = factor(DATE), y = Avgmile, fill = factor(DATE))) +
  geom_col() +
  theme_minimal() +
  labs(x = "Year", y = "Mile Pace", title = "Average Mile Pace") +
  scale_x_discrete(limits = c("2019", "2017", "2018", "2016")) +
  theme(legend.position = "none", title = element_text(face="bold"), 
        axis.title = element_text(face="bold"))

p3 <- py$gapsALL_8K %>%
  ggplot(aes(x = factor(DATE), y = gap, fill = factor(DATE))) +
  geom_col() +
  theme_minimal() +
  labs(x = "Year", y = "Gap (minutes)", title = "Average Gap") +
  scale_x_discrete(limits = c("2018", "2017", "2019", "2016")) +
  theme(legend.position = "none", title = element_text(face="bold"), 
        axis.title = element_text(face="bold"))

gridExtra::grid.arrange(p1, p2, p3, ncol = 3, nrow = 1)
```

With all other races but 8K distances filtered out, we can see that most of the results remain the same as the analysis from above. The results for the average 8K race time at meets for every year are identical - the 2019 team had the fastest average race time out of the other 3 teams, which means that runners generally were faster on this team than runners on the other teams in previous years. The margin for this is very small, as the 2017 and 2018 teams are not much slower. For the average mile pace at 8K races, the 2019 team again produces the fastest runners. Compared to the results in the previous section, the 2017 team has a slightly faster average mile pace than the 2018 team, while the opposite was true when all races were being considered. The average gap for 8K races is starkly different than the results when all the races were being considered. Here, we see that the 2018 team still had the best average minute gap between the first and fifth runner. However, the 2017 team had the second best gap at about 1 minute and 15 seconds; this team had the worst gap when all races were being considered. Consequently, the 2019 team had the third best gap at about 1 minute and 20 seconds and the 2016 team had the worst gap at 1 minute and 30 seconds. 

In conclusion, when considering only 8K races, the 2018 team had the best gap between the first and the fifth runner, meaning that they were the best at minimizing their point accumulation. However, because they did not have the fastest average 8K race times or the fastest average mile paces, this means that their point total may have been more than what is conveyed by their gap. Since they are running slower on average than other teams, that means they are allowing more runners in front of them, which means more points and a worse team finish. Nevertheless, even though the 2019 team had faster times on average, because the average gap was big, there were more runners from other teams in between the Mac Pack runners, meaning more points as well. Therefore, both situations level out and it seems that they performed similarly. Taking all this into account, though, shows how well the team stuck together and how the team may have changed over the years. 

Finally, now that we have results that only reflect 8K races, we can also find where each team had their fastest and slowest races, as well as what the fastest and slowest individual time was in each year. Something to observe is that 2019 produced the fastest individual time in these four years at 26 minutes flat at the Blugold Invitational.

```{python}
# Fastest and slowest 8K race for each year
ALL8K_fast_slow = avgTimeSummaryALL_8K.groupby("DATE").agg(
  Slowest_TeamTime = ("Time_avg", "max"),
  Fastest_TeamTime = ("Time_avg", "min"),
  Slowest_IndivTime = ("Time_max", "max"),
  Fastest_IndivTime = ("Time_min", "min"),
  Slowest_pace = ("Avgmile", "max"),
  Fastest_pace = ("Avgmile", "min"),
  Best_gap = ("gap", "min"),
  Worst_gap = ("gap", "max"))

pd.set_option('max_columns', 9)
ALL8K_fast_slow
```

The following R code produces summary statistics similar to the Python code above, but again uses the `slice()` and `which.min()` functions to find where the fastest and slowest team times, mile paces, and individual times occurred as well as the best and worst team gaps for every year. These results are then transformed into a "longer" format so that they are able to be combined and viewed together.

```{r, warning=FALSE, message=FALSE}
# Using R to see Meet and Date when finding min and max
# Separate data frames for each metric

# Fastest Time a runner got
d1 <- py$avgTimeSummaryALL_8K %>%
  group_by(DATE) %>%
  slice(which.min(Time_min)) %>%
  select(MEET, Time_min) %>%
  rename(Fastest_IndivTime = Time_min) %>%
  pivot_longer(cols = Fastest_IndivTime, names_to = "Type", values_to = "Result")

# Slowest Time a runner got
d2 <- py$avgTimeSummaryALL_8K %>%
  group_by(DATE) %>%
  slice(which.max(Time_max)) %>%
  select(MEET, Time_max) %>%
  rename(Slowest_IndivTime = Time_max) %>%
  pivot_longer(cols = Slowest_IndivTime, names_to = "Type", values_to = "Result")

# Fastest Time as team
d3 <- py$avgTimeSummaryALL_8K %>%
  group_by(DATE) %>%
  slice(which.min(Time_avg)) %>%
  select(MEET, Time_avg) %>%
  rename(Fastest_TeamTime = Time_avg) %>%
  pivot_longer(cols = Fastest_TeamTime, names_to = "Type", values_to = "Result")

# Slowest Time as a team
d4 <- py$avgTimeSummaryALL_8K %>%
  group_by(DATE) %>%
  slice(which.max(Time_avg)) %>%
  select(MEET, Time_avg) %>%
  rename(Slowest_TeamTime = Time_avg) %>%
  pivot_longer(cols = Slowest_TeamTime, names_to = "Type", values_to = "Result")

# Slowest pace as a team
d5 <- py$avgTimeSummaryALL_8K %>%
  group_by(DATE) %>%
  slice(which.max(Avgmile)) %>%
  select(MEET, Avgmile) %>%
  rename(Slowest_pace = Avgmile) %>%
  pivot_longer(cols = Slowest_pace, names_to = "Type", values_to = "Result")

# Fastest pace as a team
d6 <- py$avgTimeSummaryALL_8K %>%
  group_by(DATE) %>%
  slice(which.min(Avgmile)) %>%
  select(MEET, Avgmile ) %>%
  rename(Fastest_pace = Avgmile) %>%
  pivot_longer(cols = Fastest_pace, names_to = "Type", values_to = "Result")

# Worst gap as a team
d7 <- py$avgTimeSummaryALL_8K %>%
  group_by(DATE) %>%
  slice(which.max(gap)) %>%
  select(MEET, gap) %>%
  rename(Best_gap = gap) %>%
  pivot_longer(cols = Best_gap, names_to = "Type", values_to = "Result")

# Best gap as a team
d8 <- py$avgTimeSummaryALL_8K %>%
  group_by(DATE) %>%
  slice(which.min(gap)) %>%
  select(MEET, gap) %>%
  rename(Worst_gap = gap) %>%
  pivot_longer(cols = Worst_gap, names_to = "Type", values_to = "Result")

# Combining dataframes from above into one
ALL8K_fast_slow <- bind_rows(d1, d2, d3, d4, d5, d6, d7, d8)
ALL8K_fast_slow
```


# Conclusion

This analysis first used Python and the `Beautiful Soup` module to scrape data on meet results for the Macalester Men's Cross Country team for the seasons between 2016 and 2019 years. Then, using a combination of R packages such as `ggplot` and `lubridate` and Python modules such as `seaborn` and `pandas`, we were able to analyze runner performance and compare team performance in each of the four seasons in this sample. This gives a great overview of team and individual performances and shows how the Mac Pack has changed over the course of four years.

A special thanks to Lian for allowing me to pursue this project alone. I am grateful I was given permission to learn a new Python skill that we did not cover in class through various resources on different websites. As such, I am thankful for all the resources I found and used and I did my best to document all the pages I used as reference to show that I was able to look up how to use functions or how to write code and modify it to fit my analysis, and to give credit where it is due for this, most importantly.

