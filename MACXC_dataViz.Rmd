---
title: "Data Summary and Visualization of the MAC PACK '19"
author: "Edwin Reyes Herrera"
date: "11/5/2019"
output: 
  html_document:
    df_print: paged
    keep_md: true
---
```{python}
from tabulate import tabulate
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(style="whitegrid")
```

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(reticulate)
```

The "Mac Pack" is what the Macalester Men's Cross Country Team is fondly known as, given to our current coach Matt Haugen. He deems the "Mac Pack Era" as the time in which he has been head coach, which has been since the early 2000s. The team nickname is a play-on-words to indicate that we run in packs, which is important in cross country since the goal is to try to minimize the number of points the team collects in a meet.

# Analyzing the 2019 Cross Country Season

This reads in the csv file that was created from the python script dedicated to web scraping meet results and creating a full data frame containing information on all the meets that the men's cross country team competed in this year. It drops an unused variable left over from that process.

```{python}
MeetInfo = pd.read_csv("data/MeetTimes_19.csv")
MeetInfo = MeetInfo.drop(['Unnamed: 0'], axis=1)
```

After reading the data frame using python's `pandas` module, we are able to access it in R using the `reticulate` package and converting some columns into characters, in which Python reads in as a list. Displayed below is the data frame of 2019 results that was scraped from the Python script using `Beautiful Soup`.

```{r}
MeetInfo <- py$MeetInfo %>%
  mutate_if(is.list,as.character)

MeetInfo
```

Uisng Python's `seaborn` module, we can begon to visualize every runner's performance throughout the year. Below is a line plot showing the place each runner was on the team for every meet. The lower the place, the faster the athlete ran. We can notice that some athletes only have few data points on their graph - this reflects a missed meet. Looking at my own performance, I can see that I was consistently the same place on the team (4th) for all but one meet.

```{python}
g = sns.FacetGrid(MeetInfo, col="LASTNAME", hue = "LASTNAME", col_wrap=5)
(g.map(plt.plot,"MEET", "TEAMPLACE", marker=".")
.set_axis_labels("", "Team Place")
.set_xticklabels([]))
plt.show()
```

Moreover, we can continue to visualize how each runner performed by plotting every runner's place on a scatterplot using the meets on the x-axis. In this plot, we can better see how every runner performed relative to all other teammates and also see which runners performed better than others in a given meet. For the most part, we can see those runners that were placed 1st through 5th remained consistent for the entire year, only with some variation. This is neat because it uses `ggplot` to create a visualization from a data frame that was created in Python.

```{r}
ggplot(MeetInfo, aes(x = MEET, y = TEAMPLACE, label = LASTNAME, color = LASTNAME)) +
    geom_text(size = 3) +
    theme_minimal() +
    theme(axis.text.x=element_text(angle = 90, size = 7), legend.position ="none") +
    labs(x = "Meet", y = "Team Place", title = "Performances for Every 2019 Meet") +
    scale_y_continuous(breaks = seq(1,21, 1)) + 
    scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", 
                                "Running of the Cows (Carleton)", 
                                "Blugold Invitational", 
                                "Jim Drews Invitational (Lacrosse)", "MIAC"))
```

From the plot above, we can see that there were some meets in which not all runners competed. As such, the Python code below returns the count for the number of meets that every runner competed in. We can see some variation in this; if a runner ran seven meets, that means that they ran in all of the "regular season" meets, plus the Central Regional Meet, in which you have to qualify for. Summarizing this information was converted back into a `pandas` data frame for ease of manipulation later.

```{python}
# Summarizing the number of meets each runner competed in
runnerMeets = pd.DataFrame(MeetInfo.LASTNAME.value_counts())
runnerMeets.columns = ["Count"]
runnerMeets
```

I was interested in analyzing how many points every runner that ran in every meet (inlcuding the Central Region meet) this year accumulated. First, I retrieved a list of the names of the runners that ran in all 7 meets by filtering and saved it into an object called `scorers`. The `.index` was used to extract the names, as the names were being used as the index of the rows in the above data frame.

```{python}
scorers = list(runnerMeets[runnerMeets.Count == 6].index)
scorers
```

Then, I took the original `MeetInfo` data set that has all the information of 2019 meets and filtered to only reflect runners that were in the top 5 runner for the team in each meet. This reflects those runners that contributed to the overall team score for each meet since only the top 5 runners on each team score. This takes advantage of the `.isin()` function of pandas, which looks to filter the column of `TEAMPLACE` satisfy the condition that it is between 1 and 5.

After, we filter again, but this time use the `scorers` list created above to filter and only keep the names of the runners that were in the top 5 runners on the team, and now also that ran in all 7 meets of the year. Finally, we summed up the total score each runner accumulated throughout the year. The `reset_index()` converts the names that are the row's index to a column.

```{python}
top5Scores = MeetInfo[MeetInfo.TEAMPLACE.isin(range(1,6))]
top5Scores = top5Scores[top5Scores.LASTNAME.isin(scorers)]
top5Scores = top5Scores.groupby("LASTNAME").sum()[['SCORE']].reset_index()
top5Scores
```

We can also visualize the summary output above in a barplot. What we can deduce from the summary table and the barplot is that these were the runners that were consistently in the top 5 runners on the team for every meet. It was important to only consider those runners that ran in all meets. This is because if there was a runner that only ran in some meets, and was a scoring runner, then their point accumulation would be lower than everyone else's. 

In addition, we can also see that their total point accumulation reflects what place on the team they usually came in at. What is interesting to note is that the points that Lepak accumulated isn't that much more less than the points Johnson accumulated. This means that Lepak was not always the number one runner and sometimes placed lower on the team, which contributed to almost having the same total points as Johnson. As such, this plot does a great job of indicating the trajectory of the runners and the place they were on the team. In the end, taking into consideration all meets, Lepak was the number one runner for the 2019 year even if he did have some races where he did not finish number one.

```{python}
plot = sns.barplot(x="LASTNAME", y="SCORE", data=top5Scores)
plot.set_title("Points Accumulated at 2019 Meets for Top 5 Runners", fontsize = 15)
plot.set_xlabel("Runner")
plot.set_ylabel("Points")
```

From there, I was also curious to analyze everyone's perfromance based on their times for each race. The problem was that when the data was scraped, the times were saved as strings, so there was a need to convert these strings into numeric data. Luckily, R has a package called `lubridate` that is exceptional for working with dates and times.

Using the Python data frame, we update the `MeetInfo` using R and `lubridate` to convert the times reflected in the variables of `TIME` (final time for a meet) and `Avg. Mile` (average mile during a race) from strings to numeric data. We indicate that we want our data to be converted to minutes.

```{r, warning=FALSE}
MeetInfo <- MeetInfo %>%
  mutate(TIME = time_length(ms(TIME), unit = "minute"),
         `Avg. Mile` = time_length(ms(`Avg. Mile`), unit = "minute"))

MeetInfo
```

Using the updated dateframe above, we are able to make a similar line plot to the one above, this time plotting every runner's trajectory based on their total time for a race. It is important to note that not all races were the same distance - some were only 4 miles, while the typical race is an 8k. To account for this (i.e. avoid any misleading information on the plot when someone's time suddenly decreases), I ordered the x-axis so as to place those meets that were only 4 miles at the beginning.

```{r, warning=FALSE}
#Visualizing runner performance by final race time for each race
ggplot(MeetInfo, aes(x = MEET, y = TIME, color = LASTNAME, group = LASTNAME)) + geom_point() +
    geom_line() +
    theme_minimal() +
    facet_wrap(vars(LASTNAME), ncol = 4) +
  labs(x = "Meet", y = "Race Time", title = "Race Time for Every 2019 Teammate",
       subtitle = "Every Meet") +
    theme(axis.text.x=element_text(angle = 90), legend.position ="none") +
    scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "MIAC"))
```

Another way to control for difference in distances for meets is to plot a runner's trajectory using their average mile pace for a race. In this way, all races are on the same scale and this gives a better perspective on whether a runner ran faster or slower relative to other meets. Looking at my own progression, I generally became faster as the year went on, with a small increase in time in the second and 3rd meets. (Note: the order of the x-axis also reflects the order of meets that we competed in, by chance! So this does in fact show progression throughout the year in chronological order). The absence of dots or breaks in the line show missed meets or DNFs (did not finish).

```{r, warning=FALSE}
# Visualizing runner performance based on average mile for each race
ggplot(MeetInfo, aes(x = MEET, y = `Avg. Mile`, color = LASTNAME, group = LASTNAME)) + geom_point() +
    geom_line() +
    theme_minimal() +
    facet_wrap(vars(LASTNAME)) +
    labs(x = "Meet", y = "Average Mile Pace", 
         title = "Averga Mile Pace for Every 2019 Teammate", subtitle = "Every Meet") +
    theme(axis.text.x=element_text(angle = 90), legend.position ="none") +
    scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Running of the Cows (Carleton)","Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "MIAC"))
```

Another neat thing about this analysis is that even though I changed the original data set that was created in Python in R, I am able to return that data frame so that the Python engine can begin using it again, which is what is done below.

Now that we have visualized every runner's individual performance for the 2019 year, I wanted to analyze the time gap between the first and the 5th runner on the team. Generally, the bigger the gap, the more points that the team accumulates and the worse that the team places overall in a meet.

First, we return the updated data frame of `MeetInfo` into python after manipulating it in Python and assing it to the variable `avgTime` anf filter to only have the top 5 runners for each meet. Then, we group by every meet and use `pandas` `agg()` function to apply three summary statistics for each meet: the fastest time at every meet (min), the slowest time at every meet (max), and the average time at every meet (mean). Then we take advantage of `pandas` `.assign()` function to create a new variable called `gap` that takes the difference in the slowest and fastest time to find the gap in minutes for every meet.

We can observe that the team had the smallest gap between the first and last runner that scored in the Twin Cities Invitational, which was our first race of the year. The gap is about 0.75 minutes, which is about 45 seconds. This is intuitive considering that this was also the meet in which we placed the highest (2nd place overall). This metric, again, controls for the fact that some races were different distances.

Looking at the races that were 8k distances, we see that the best team finish was the MIAC meet, which was our conference championships. Interestingly, this was a meet in which all runners finished closest to each other, but the average time for this meet is only the third fastest out of all the meets. This means that everyone ran slower at this meet even though the gap was smaller, leading to a worse finish than what is seen on the surface.

```{python}
avgTime = r.MeetInfo[r.MeetInfo.TEAMPLACE <= 5]
avgTime = pd.DataFrame(avgTime.groupby("MEET").
  agg({"TIME": ["min", "max", "mean"]}).
  rename(columns = {"min":"Time_min", "max":"Time_max", "mean": "AvgTime"}))

avgTimeSummary = avgTime["TIME"].assign(gap = avgTime["TIME"]["Time_max"] - avgTime["TIME"]["Time_min"])

avgTimeSummary = avgTimeSummary.reset_index()
avgTimeSummary
```

We can also calculate the average gap between the 1st and 5th runner for the year, which ended up being about 1 minute and 15 seconds.

```{python}
# Getting average gap between 1st and 5th man for 2019
avgTimeSummary["gap"].mean().round(4)
```

# Analyzing the 2016-2019 Seasons

Now that we have analyzed performances for the 2019 cross country season, we can apply the same analysis to *all* races during my four years here at Macalester.

First, we load the data set containing information on all meets for the four years using Python and assign it to `MeetALL`.

```{python}
MeetALL = pd.read_csv("data/MeetALL.csv")
MeetALL = MeetALL.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)
```

Then we also create it as an R data frame to be able to easily manipulate it.

```{r}
MeetALL <- py$MeetALL %>%
  mutate_if(is_list, as.character)

MeetALL
```

Now that it is an R object, we can again use the `lubridate` package to convert the average mile pace and total time for every meet to numeric data on the minutes scale from string objects just as above.

```{r}
# Converting Time and Average Mile columns to integers using lubridate
MeetALL <- MeetALL %>%
  mutate(TIME = time_length(ms(TIME), unit = "minute"),
         `Avg. Mile` = time_length(ms(`Avg. Mile`), unit = "minute"))

MeetALL
```

Then, the updated `MeetALL` data frame is called back into Python, and we find the slowest, fastest, and average time for each meet for every year only for the top 5 runners in each meet, and also calculate the gaps between the first and fifth runner for every meet - this is all saved into `avgTimeSummaryALL`. An additional summary statistic that we will calculate here is the average mile pace for every meet for every year.

```{python}
# Calling data frame back into python
avgTimeALL = r.MeetALL[r.MeetALL.TEAMPLACE <= 5]
avgTimeALL = pd.DataFrame(avgTimeALL.groupby(["MEET", "DATE"]).agg(
  Time_min = ("TIME", "min"),
  Time_max = ("TIME", "max"),
  Time_avg = ("TIME", "mean"),
  Avgmile = ("Avg. Mile", "mean")).reset_index())

avgTimeSummaryALL = avgTimeALL.assign(
  gap = avgTimeALL["Time_max"] - avgTimeALL["Time_min"]
)

avgTimeSummaryALL
```

Now that we have information on all four years, we can determine which Mac Pack team in this four year span was the "best" in terms of gap between the first and last runners who score. We group by year and find the average gap for every meet for every year and visualize the results in a barplot. We can see that during my four years at Macalester, the "best" team was in 2018 with a gap of about 50 seconds, followed by the 2019 team with an average gap of about 1 minute and 15 seconds.

I was wondering which team also contributed the least amount of points throughout the year, but teams were unable to be compared since some teams ran in more meets than others, so the point accumulation would not be representative of performance in this case.

```{python}
gapsALL = pd.DataFrame(avgTimeSummaryALL.groupby("DATE")
  .mean()["gap"]).reset_index()
  
plot = sns.barplot(x="DATE", y = "gap", data = gapsALL, order= [2018.0, 2019.0, 2016.0, 2017.0])
plot.set_title("Average Gap (min) between 1st Runner and 5th Runner", fontsize = 15)
plot.set_xlabel("Year")
plot.set_ylabel("Gap (Minutes)")
```

We can also visualize race performance using the data we gathered above on average time and average gap for every meet for every year. The plot below shows the average time for every meet across all four years. Again, those races that were not an 8k distance (now including 4 mile and 5k races) were place at the beginning fo the plot (going left to right) to avoid any misonceptions about the time.

In this plot, we can observe that the 2018 and 2019 years ran less in meets than in 2017 or 2016 teams, which may be a factor in why their gaps were much better. The 2018 team's times stayed very consistent, while the 2019 team had slightly more variability in times. The second plot communicates the same information except all the years are visualized on the same plot, making it easier for comparison.

```{r}
py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = Time_avg, color = factor(DATE), group = DATE))+
  geom_line() +
  geom_point() +
  facet_grid(rows = vars(DATE)) +
  labs(x = "Meet", y = "Average Time (minutes)", color = "Year", title = "Average Time", subtitle = "For Every Meet in a Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_y_continuous(breaks = seq(20,32,2)) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))

py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = Time_avg, color = factor(DATE), group = DATE))+
  geom_line() +
  geom_point() +
  labs(x = "Meet", y = "Average Time (minutes)", color = "Year", title = "Average Time", subtitle = "For Every Meet in a Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_y_continuous(breaks = seq(20,32,2)) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))
```

Furthermore, we can also create a visualization of all the time gaps for every meet in every year. Interestingly, we see that the best team finish in this four year span was in 2018 for the Griak meet, where the gap was only 30 seconds. We can also observe that the gaps in 2018 alwways were around a minute or below, while the gaps in 2019 were variable and consistently over a minute. Again, the second plot allows for more concrete comparisons.

```{r}
py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = gap, color = factor(DATE), group = DATE))+
  geom_line() +
  geom_point() +
  facet_grid(rows = vars(DATE), ) +
  labs(x = "Meet", y = "Gap (minutes)", color = "Year", title = "Gap Between 1st and 5th Runner", subtitle = "For Every Meet in a Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))

py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = gap, color = factor(DATE), group = DATE))+
  geom_line() +
  geom_point() +
  labs(x = "Meet", y = "Gap (minutes)", color = "Year", title = "Gap Between 1st and 5th Runner", subtitle = "For Every Meet in a Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))
```

Finally, we can also calculate average mile pace for the scoring runners for every meet for every year in this time span. This again would place all meets on the same scale and would be a better metric to compare performance at every meet for each year.

```{r}
py$avgTimeSummaryALL %>%
  ggplot(aes(x = MEET, y = Avgmile, color = factor(DATE), group = DATE)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Meet", y = "Average Mile", color = "Year", 
       title = "Overall Average Mile for Team", subtitle = "For Every Year") +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))
```

From the plots above, we can see how each team did compared to others for the same meets. As was mentioned before, the 2018 team in general was the "best" in most of the metrics above, though in some other years, the team had a fast average time for a meet or a smaller gap between runners. It is important to take into consideration both gap and overall average mile for the team because a gap between runners can be small, but if they all ran relatively slow, then the point totals would be higher. Similarly, if the average time for a meet was very fast, but the gap was large, then the point total would also be large. As such, we can only deduce from the beginning of this analysis that the team with the smallest gap between runners was the 2018 squad. However, taking into consideration the plots below, we see that the 2019 team had both the fastest average mile and fastest overall average time. Therefore, the 2019 in reality may have been slightly better than the 2018 team, though the 2018 team did have the bets finish in Mac Pack team history, which may have been what gave them the margin in having the best gap. Of course, every team ran in different meets throughout the year and some ran more than others, so some of these comparisons may not be fair. However, this analysis still is able to visualize the team's trajectory throughout the year.

```{python}
avgMileALL = pd.DataFrame(avgTimeSummaryALL.groupby("DATE")
  .mean()["Avgmile"]).reset_index()

avgMileALL
  
plot = sns.barplot(x="DATE", y = "Avgmile", data = avgMileALL, order= [2019.0, 2018.0, 2017.0, 2016.0])
plot.set_title("Average Mile for all Meets", fontsize = 15)
plot.set_xlabel("Year")
plot.set_ylabel("Average Mile")
```

```{python}
avgTimeALL = pd.DataFrame(avgTimeSummaryALL.groupby("DATE")
  .mean()["Time_avg"]).reset_index()

avgTimeALL
  
plot = sns.barplot(x="DATE", y = "Time_avg", data = avgTimeALL, order= [2019.0, 2017.0, 2017.0, 2018.0])
plot.set_title("Average Time for all Meets", fontsize = 15)
plot.set_xlabel("Year")
plot.set_ylabel("Average Time")
```

# Analyzing the Class of 2020

A final aspect of this web scraping project I was interested in investigating was visualizing the trajectory of the Class of 2020 teammates during our four years at Macalester. Using Python, I created a list with the remaining Class of 2020 teammates.

```{python}
class_2020 = ["Reyes Herrera", "Lepak", "Jarka-Sellers", "Milner", "Bildsten", "O'Donnell-Hoff", "Hernandez"]
```

Then using the list above, I filtered the `MeetALL` data from above based on the list above using `.isin()` and saved this new data frame to an object called `seniors`.

```{python}
MeetALL = r.MeetALL
seniors = pd.DataFrame(MeetALL[MeetALL.LASTNAME.isin(class_2020)])
seniors
```

Now only having information on the Class of 2020, I plotted each of the seven members performances using their final time for every meet between the span of 2016-2019.

```{r, }
py$seniors %>%
  ggplot(aes(x = MEET, y = TIME, color = LASTNAME, group = LASTNAME)) +
  geom_line() +
  geom_point() +
  facet_grid(rows = vars(DATE), cols = vars(LASTNAME)) +
  theme_minimal() +
  labs(y = "Final Race Time", title = "Class of 2020 Race Time For Every Meet", 
       subtitle = "2016-2019") +
  theme(axis.text.x = element_text(angle = 90, size = 5)) +
  scale_x_discrete(limits = c("Twin Cities Invitational", "Summit Cup", "Augsburg Open", "Running of the Cows (Carleton)",
                              "Blugold Invitational", "Jim Drews Invitational (Lacrosse)", "Falcon Invite", "River Falls", 
                              "St. Olaf Invitational", "Oshkosh", "Griak", "MIAC", "Central Region"))
```

From there, I wanted to see how the average time for a given year changed for each member of the Class of 2020. I grouped by the team member and the date and calculated the average race time and average mile pace for each team member for every year.

```{python}
seniorsAvg = seniors.groupby(["LASTNAME", "DATE"]).agg(
  Time_avg = ("TIME", "mean"),
  Avgmile = ("Avg. Mile", "mean"))
seniorsAvg = pd.DataFrame(seniorsAvg.reset_index())
seniorsAvg
```

When visualizing this, we can see for the most part that everyone had a falling trend, which means that in general, all members became faster over the course of the four years.

```{r}
# Average Race Time per year
py$seniorsAvg %>%
  ggplot(aes(x = factor(DATE), y = Time_avg, color = LASTNAME, group = LASTNAME)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(x = "Average Race Time", y = "Year", color = "Runner", 
       title = "Average Race Time For 2016-2019 Seasons", subtitle = "Class of 2020")

# Average Mile Time per Year
py$seniorsAvg %>%
  ggplot(aes(x = factor(DATE), y = Avgmile, color = LASTNAME, group = LASTNAME)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(x = "Average Mile", y = "Year", color = "Runner", 
       title = "Average Mile Pace For 2016-2019 Seasons", subtitle = "Class of 2020")
```

In addition, we can also determine where and when each member of the Class of 2020 had their fastest and and slowest race. For this analysis, however, it is important to filter out the races that were not an 8k distance, since those races would be the fastest for everyone. More importantly, the culmination of a season is getting a personal best in the 8k. An approach to do this is how we handled filtering out the Class of 2020 using the `.isn()` function and passing through a list. However, another method is creating a new variable `Type` that designates if a race was an 8k, or another distance, as seen below using `numpy` and its `select` function.

```{python}
conditions = [
    (seniors["MEET"] == "Summit Cup") | (seniors["MEET"] == "Twin Cities Invitational"),
    (seniors["MEET"] == "Augsburg Open")
    ]
choices = ['4 Mile', '5K']

seniors['Type'] = np.select(conditions, choices, default='8K')

seniors
```

From there, we can filter using the new `Type` column and only selecting 8K races. Afterwards, we can group by runner and find the `max` and `min` for final race time.

```{python}
seniors_8K = seniors[seniors["Type"] == "8K"]

seniors_best = seniors_8K.groupby("LASTNAME").agg(
  Slowest_Time = ("TIME", "max"),
  Fastest_Time = ("TIME", "min")).reset_index()

seniors_best
```

A way to visualize every senior's fast and slowest way is to change the data frame from above to be a longer data frame so that we have a column that designates if it was a runner's fastest or slowest timem and a column that is the time in minutes. The code below uses the `stack()` function from `pandas` to create new variables called `Type` and `Race Time` which allows us ot create a double bar graph for all runers showing their fastest and slowest times.

```{python}
# Pivot Longer
seniors_best.set_index("LASTNAME").stack().reset_index().rename(columns = {0:"Race Time", "level_1":"Type"})

plot = sns.barplot(x="LASTNAME", y="Race Time", hue= "Type", data= seniors_best.set_index("LASTNAME").stack().reset_index().rename(columns = {0:"Race Time", "level_1":"Type"}))
plot.set_title("Fastest and Slowest 8K Times for Class of 202", fontsize = 15)
plot.set_xlabel("Runner")
plot.set_ylabel("Time")
```

The using R, we are able to see all the details from a senior's fastest and slowest races - namely, when and where those races were. This is accomplished using R's `slice` and `which.min` functions. We can observe, for example, that I had my fastest race at the Blugold Invitational in 2019 and my slowest at the St. Olaf Invitational in 2017.

```{r}
# Using R to see Meet and Date when finding min and max

# Fastest Times
py$seniors_8K %>%
  group_by(LASTNAME) %>%
  slice(which.min(TIME)) %>%
  select(LASTNAME, MEET, TIME, DATE)

# Slowest Times
py$seniors_8K %>%
  group_by(LASTNAME) %>%
  slice(which.max(TIME)) %>%
  select(LASTNAME, MEET, TIME, DATE)
```

In addition, now that we have a data frame in which all the non-8K meets are filtered out, we can also use `seaborn` to create a boxplot to show the distribution of race times for each runner. We can see that Lepak had the lowest range, while Hernandez had the largest.

```{python}
#Range of Times for Class 0f 2020 throughout the years
plot = sns.boxplot(x= "LASTNAME", y= "TIME", data = seniors_8K)
plot.set_title("Range of 8K Times for Class of 202 Runners", fontsize = 15)
plot.set_xlabel("Runner")
plot.set_ylabel("Race Time")
```

# Reanalyzing 2016-2019 Seasons Using only 8K times

Now that we have a method to only analyze 8K times, we return to comparing all four seasons based only on 8K times. We will repeat the analysis and visualizations above, but this time using only 8K meets.

We are frist interested in comparing the range of 8K times for every year, so we take the original ``avgTimeALL` pandas data frame from the second section that has infromation on the top 5 runners from all years and filter out non-8K races using the list and `.isnin()` method we used before the previous section.`MeetALL` data frame that was manipulated in R to convert the times into numeric types, call it back into Python, and filter out the non-8K races using the list and `.isin()` method. It is important to note that the tilde here is needed, which is equivalent to `=!`.

```{python}
non8K = ["Summit Cup", "Twin Cities Invitational", "Augsburg Open"]
avgTimeALL_8K = r.MeetALL[r.MeetALL.TEAMPLACE <= 5]
avgTimeALL_8K = avgTimeALL_8K[~avgTimeALL_8K.MEET.isin(non8K)]
```

Then, we are able to calculate summary statistics and use a `seaborn` boxplot to understand the range of 8K times for each year. We can see that the 2016 team had the highest range in times as the standard deviation is about 0.85, while 2018 had the lowest range in times. Nevertheless, the mean and median times for 2018 are higher than that of the 2019 times, which means the the 2019 team had faster times at meets even though the 2018 team had a smaller range.

```{python}
#Range of 8K times for each Year
avgTimeALL_8K.groupby("DATE").agg(
mean = ("TIME", "mean"),
median = ("TIME", "median"),
sd = ("TIME", "std")
)

plot = sns.boxplot(x= "DATE", y= "TIME", data = seniors_8K)
plot.set_title("Range of 8K Times for 2016-2019 Seasons", fontsize = 15)
plot.set_xlabel("Year")
plot.set_ylabel("Race Time")
```

Now, using the technique from the previous section we take the `avgTimeSummaryALL` data frame that summarizes the average race time, mile pace, and gap between runners for all meets across the four years created in the second section above and add a new variable called `Type` that designates the distance of the race.

```{python}
conditions = [
    (avgTimeSummaryALL["MEET"] == "Summit Cup") | (avgTimeSummaryALL["MEET"] == "Twin Cities Invitational"),
    (avgTimeSummaryALL["MEET"] == "Augsburg Open")
    ]
choices = ['4 Mile', '5K']

avgTimeSummaryALL['Type'] = np.select(conditions, choices, default='8K')
avgTimeSummaryALL
```

Then using the new column, we choose only the races which are 8K distance to analyze.

```{python}
avgTimeSummaryALL_8K = avgTimeSummaryALL[avgTimeSummaryALL["Type"] == "8K"]
```

```{python}
avgTimeALL_8K = pd.DataFrame(avgTimeSummaryALL_8K.groupby("DATE")
  .mean()["Time_avg"]).reset_index()

avgTimeALL_8K

avgMileALL_8K = pd.DataFrame(avgTimeSummaryALL_8K.groupby("DATE")
  .mean()["Avgmile"]).reset_index()

avgMileALL_8K

gapsALL_8K = pd.DataFrame(avgTimeSummaryALL_8K.groupby("DATE")
  .mean()["gap"]).reset_index()
gapsALL_8K
```

